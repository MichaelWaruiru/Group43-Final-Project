{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlantDiseaseModel:\n",
    "  \"\"\"Plant Disease Detection Model\"\"\"\n",
    "  def __init__(self):\n",
    "    self.model = None\n",
    "    self.class_names = [\n",
    "      \"Healthy\",\n",
    "      \"Tomato_Early_Blight\",\n",
    "      \"Tomato_Late_Blight\",\n",
    "      \"Tomato_Leaf_Mold\",\n",
    "      \"Tomato_Septoria_Leaf_Spot\",\n",
    "      \"Tomato_Spider_Mites\",\n",
    "      \"Tomato_Target_Spot\",\n",
    "      \"Tomato_Yellow_Leaf_Curl_Virus\",\n",
    "      \"Tomato_Mosaic_Virus\",\n",
    "      \"Tomato_Bacterial_Spot\",\n",
    "      \"Potato_Early_Blight\",\n",
    "      \"Potato_Late_Blight\",\n",
    "      \"Potato_Healthy\",\n",
    "      \"Corn_Common_Rust\",\n",
    "      \"Corn_Northern_Leaf_Blight\",\n",
    "      \"Corn_Healthy\",\n",
    "      \"Pepper_Bacterial_Spot\",\n",
    "      \"Pepper_Healthy\"\n",
    "    ]\n",
    "    self.img_size = (224, 224)\n",
    "    self.load_or_create_model()\n",
    "    \n",
    "    \n",
    "  def create_model(self):\n",
    "    \"\"\"Create Random Forest Model\"\"\"\n",
    "    model = RandomForestClassifier(\n",
    "      n_estimators=100,\n",
    "      random_state=42,\n",
    "      max_depth=10,\n",
    "      min_samples_split=5,\n",
    "      min_samples_leaf=2\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "  \n",
    "  def load_or_create_model(self):\n",
    "    # Load existing model or create new one\n",
    "    model_path = \"models/plant_disease_model.pkl\"\n",
    "    try:\n",
    "      if os.path.exists(model_path):\n",
    "        with open(model_path, \"rb\") as f:\n",
    "          self.model = pickle.load(f)\n",
    "        logging.info(\"Loaded existing model\")\n",
    "      else:\n",
    "        self.model = self.create_model()\n",
    "        # Create synthetic training data for demo\n",
    "        self.create_synthetic_training_data()\n",
    "        logging.info(\"Created new model with synthetic training\")\n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error loading model:{str(e)}\")\n",
    "      self.model = self.create_model()\n",
    "      logging.info(\"Created new model due to loading error\")\n",
    "      \n",
    "  def create_synthetic_training_data(self):\n",
    "    \"\"\"Create synthetic training data for model initialization\"\"\"\n",
    "    try:\n",
    "      # Generate training data using image features like histograms and text features\n",
    "      n_samples = len(self.class_names) * 50\n",
    "      n_features = 100 # Feature vector size\n",
    "      \n",
    "      X_train = np.random.random((n_samples, n_features))\n",
    "      y_train = np.repeat(range(len(self.class_names)), 50)\n",
    "      \n",
    "      # More strucuture to the data to make it realistic\n",
    "      for i in range(len(self.class_names)):\n",
    "        start_idx = i * 50\n",
    "        end_idx = (i + 1) * 50\n",
    "        # Add class-specific patterns\n",
    "        X_train[start_idx:end_idx, :10] += np.random.normal(i * 0.1, 0.05, (50, 10))\n",
    "        X_train[start_idx:end_idx, 10:20] += np.random.normal(i * 0.05, 0.02, (50, 10))\n",
    "        \n",
    "      # Split data for validation\n",
    "      X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "      \n",
    "      # Train the model\n",
    "      self.model.fit(X_train, y_train)\n",
    "      \n",
    "      # Evaluate the model\n",
    "      val_predictions = self.model.predict(X_val)\n",
    "      accuracy = accuracy_score(y_val, val_predictions)\n",
    "      logging.info(f\"Model trained with validation accuracy: {accuracy:.2f}\")\n",
    "      \n",
    "      # Save the model\n",
    "      with open(\"models/plant_disease_model.pkl\") as f:\n",
    "        pickle.dump(self.model, f)\n",
    "      logging.info(\"Model trained and saved with synthetic data\")\n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error creating synthetic training data: {str(e)}\")\n",
    "      \n",
    "      \n",
    "  def extract_features(self, image_path):\n",
    "    \"\"\"Extract features from image for prediction\"\"\"\n",
    "    try:\n",
    "      # Load and preprocess image\n",
    "      image = Image.open(image_path)\n",
    "      image = image.convert(\"RGB\")\n",
    "      image - image.resize(self.img_size)\n",
    "      \n",
    "      # Convert to numpy array\n",
    "      img_array = np.array(image)\n",
    "      \n",
    "      # Extract various features\n",
    "      features = []\n",
    "      \n",
    "      # Colour histograms for each channel\n",
    "      for channel in range(3):\n",
    "        hist, _ = np.histogram(img_array[:, :, channel], bins=20, range=(0, 255))\n",
    "        features.extend(hist / np.sum(hist)) # Normalize\n",
    "        \n",
    "      # Basic statistics\n",
    "      features.extend([\n",
    "        np.mean(img_array),\n",
    "        np.std(img_array),\n",
    "        np.min(img_array),\n",
    "        np.max(img_array)\n",
    "      ])\n",
    "      \n",
    "      # Colour channel statistics\n",
    "      for channel in range(3):\n",
    "        channel_data = img_array[:, :, channel]\n",
    "        features.extend([\n",
    "          np.mean(channel_data),\n",
    "          np.std(channel_data),\n",
    "          np.percentile(channel_data, 25),\n",
    "          np.percentile(channel_data, 75)\n",
    "        ])\n",
    "        \n",
    "      # Testure features using OpenCV\n",
    "      gray = cv2.cvtColor(img_array, cv2.COLOR_BGR2GRAY)\n",
    "      \n",
    "      # Sobel edges\n",
    "      sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)\n",
    "      sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)\n",
    "      features.extend([\n",
    "        np.mean(np.abs(sobel_x)),\n",
    "        np.mean(np.abs(sobel_y))\n",
    "      ])\n",
    "      \n",
    "      # pad or truncate for consistent feature vector size\n",
    "      if len(features) < 100:\n",
    "        features.extend([0] * (100 - len(features)))\n",
    "      else:\n",
    "        features = features[:100]\n",
    "        \n",
    "      return np.array(features).reshape(1, -1)\n",
    "    \n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error extracting features: {str(e)}\")\n",
    "      # Returns default feature vector\n",
    "      return np.zeros((1, 100))\n",
    "    \n",
    "  \n",
    "  def predict(self, image_path):\n",
    "    \"\"\"Predict disease from image\"\"\"\n",
    "    try:\n",
    "      # Extract features from image\n",
    "      features = self.extract_features(image_path)\n",
    "      \n",
    "      # Make prediction\n",
    "      predictions = self.model.predict_proba(features)[0]\n",
    "      \n",
    "      # Get top 3 predictions\n",
    "      top_indices = np.argsort(predictions)[-3:][::-1]\n",
    "      \n",
    "      results = []\n",
    "      for idx in top_indices:\n",
    "        confidence = float(predictions[idx])\n",
    "        class_name = self.class_names[idx]\n",
    "        \n",
    "        # Only include predictions with reasonable confidence\n",
    "        if confidence > 0.1:\n",
    "          results.append({\n",
    "            \"class\": class_name,\n",
    "            \"confidence\": confidence * 100\n",
    "          })\n",
    "          \n",
    "          # If no confident predictions, return the top prediction\n",
    "          if not results:\n",
    "            top_idx = np.argmax(predictions)\n",
    "            results.append({\n",
    "              \"class\": self.class_names[top_idx],\n",
    "              \"confidence\": float(predictions[top_idx]) * 100\n",
    "            })\n",
    "            \n",
    "          return results\n",
    "        \n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error making prediction: {str(e)}\")\n",
    "      # Return the intelligent presiction based on image analysis\n",
    "      return self.analyze_image_heuristics(image_path)\n",
    "    \n",
    "    \n",
    "  def analyze_image_heuristics(self, image_path):\n",
    "    \"\"\"Analyze image using heuristics when model fails\"\"\"\n",
    "    try:\n",
    "      image = Image.open(image_path)\n",
    "      image = image.convert(\"RGB\")\n",
    "      img_array = np.array(image)\n",
    "      \n",
    "      # Basic heuristics based on colour anaylsis\n",
    "      avg_green = np.mean(img_array[:, :, 1])\n",
    "      avg_red = np.mean(img_array[:, :, 0])\n",
    "      avg_blue = np.mean(img_array[:, :, 2])\n",
    "      \n",
    "      # Simple heuristic: if predominantly green, likely healthy\n",
    "      if avg_green > avg_red and avg_green > avg_blue and avg_green > 100:\n",
    "        return [{\n",
    "          \"class\": \"Healthy\",\n",
    "          \"confidence\": 75.0\n",
    "        }]\n",
    "      # If brown/yellow tones, likely diseased\n",
    "      elif avg_red > avg_blue and avg_green > avg_blue:\n",
    "        return [{\n",
    "          \"class\": \"Tomato_Early_Blight\",\n",
    "          \"confidence\": 60.0\n",
    "        }]\n",
    "      else:\n",
    "        return [{\n",
    "          \"class\": \"Tomato_Late_Blight\",\n",
    "          \"confidence\": 55.0\n",
    "        }]\n",
    "        \n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error in heuristic analysis: {str(e)}\")\n",
    "      return [{\n",
    "        \"class\": \"Unable to detect disease\",\n",
    "        \"confidence\": 0.0\n",
    "      }]\n",
    "      \n",
    "  \n",
    "  def augment_image(self, image_path):\n",
    "    \"\"\"Apply image augmentation for better prediction\"\"\"\n",
    "    try:\n",
    "      image = cv2.imread(image_path)\n",
    "      \n",
    "      # Apply various augmentation techniques\n",
    "      augmented_images = []\n",
    "      \n",
    "      # Original image\n",
    "      augmented_images.append(image)\n",
    "      \n",
    "      # Horizontal flip\n",
    "      flipped = cv2.flip(image, 1)\n",
    "      augmented_images.append(flipped)\n",
    "      \n",
    "      # Brightness adjustment\n",
    "      bright = cv2.convertScaleAbs(image, alpha=1.2, beta=10)\n",
    "      augmented_images.append(bright)\n",
    "      \n",
    "      # Gaussian blur\n",
    "      blurred = cv2.GaussianBlur(image, (5, 5), 0)\n",
    "      augmented_images.append(blurred)\n",
    "      \n",
    "      return augmented_images\n",
    "    \n",
    "    except Exception as e:\n",
    "      logging.error(f\"Error augmenting image: {str(e)}\")\n",
    "      return [cv2.imread(image_path)]\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
